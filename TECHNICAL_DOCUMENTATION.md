# Dry Bean Type Classification System
## Professional Technical Documentation

---

## ðŸ“‘ Table of Contents
1. [Executive Summary](#executive-summary)
2. [System Architecture](#system-architecture)
3. [Streamlit Web Interface](#streamlit-web-interface)
4. [Machine Learning Model](#machine-learning-model)
5. [Technical Implementation](#technical-implementation)
6. [Installation & Deployment](#installation--deployment)
7. [Usage Guidelines](#usage-guidelines)
8. [Performance Metrics](#performance-metrics)

---

## Executive Summary

The **Dry Bean Type Classification System** is a state-of-the-art machine learning solution designed to automatically classify dry beans into seven distinct categories using morphological feature analysis. This system integrates advanced computer vision-based feature extraction with a robust supervised learning model, wrapped in an intuitive web interface for seamless real-world application.

### Key Capabilities:
- **Real-time Classification**: Instantaneous bean type prediction based on 16 morphological features
- **High Accuracy**: Trained on 13,611 diverse bean samples
- **7-Class Classification**: SEKER, BARBUNYA, BOMBAY, CALI, HOROZ, SIRA, DERMASON
- **User-Friendly Interface**: Interactive Streamlit web application
- **Scalable Architecture**: Production-ready deployment

---

## System Architecture

### End-to-End Pipeline

```
Physical Bean
    â†“
Image Acquisition
    â†“
Feature Extraction (16 Morphological Features)
    â†“
Feature Preprocessing (StandardScaler)
    â†“
ML Model Prediction
    â†“
Classification Output + Confidence Scores
```

### Component Overview

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Frontend** | Streamlit | Web interface for user interaction |
| **Backend** | Python/Scikit-learn | Model inference and predictions |
| **Data Processing** | NumPy/Pandas | Feature processing and transformation |
| **Model Storage** | Joblib | Serialized model persistence |
| **Deployment** | Streamlit Cloud/Local | Application hosting |

---

## Streamlit Web Interface

### Application Overview

The Streamlit application provides an interactive, responsive interface for bean classification with the following components:

### ðŸŽ¨ Interface Components

#### 1. **Header Section**
```
ðŸŒ± Dry Bean Type Classification
Enter physical measurements of a dry bean to predict its class.
```
- Clear title with emoji for visual appeal
- Descriptive subtitle explaining functionality

#### 2. **Input Form Section**

The application presents 16 numerical input fields in an organized layout:

**Feature Input Panel:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Area                    [____0.0____]  â”‚
â”‚  Perimeter               [____0.0____]  â”‚
â”‚  Major Axis Length       [____0.0____]  â”‚
â”‚  Minor Axis Length       [____0.0____]  â”‚
â”‚  Aspect Ratio            [____0.0____]  â”‚
â”‚  Eccentricity            [____0.0____]  â”‚
â”‚  Convex Area             [____0.0____]  â”‚
â”‚  Equivalent Diameter     [____0.0____]  â”‚
â”‚  Extent                  [____0.0____]  â”‚
â”‚  Solidity                [____0.0____]  â”‚
â”‚  Roundness               [____0.0____]  â”‚
â”‚  Compactness             [____0.0____]  â”‚
â”‚  ShapeFactor1            [____0.0____]  â”‚
â”‚  ShapeFactor2            [____0.0____]  â”‚
â”‚  ShapeFactor3            [____0.0____]  â”‚
â”‚  ShapeFactor4            [____0.0____]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Input Specifications:**
- Minimum Value: 0.0
- Step Increment: 0.01
- Default Value: 0.0
- Data Type: Floating-point numbers

#### 3. **Prediction Control**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [Predict Bean Type]    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- Single action button triggering classification
- Centered layout for easy access
- Clear action label

#### 4. **Output Display**

Upon prediction, the application displays:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  âœ… Predicted Bean Type: DERMASON    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Output Features:**
- Success indicator with checkmark emoji
- Bold classification result
- Green highlight for positive outcomes
- Real-time result generation

### ðŸ› ï¸ Technical Configuration

```python
st.set_page_config(
    page_title="Dry Bean Classifier",
    layout="centered"
)
```

- **Page Title**: Displayed in browser tab and metadata
- **Layout**: Centered layout for optimal mobile and desktop experience
- **Responsive Design**: Automatically adapts to screen size

### ðŸ’¾ Backend Operations

When "Predict Bean Type" button is clicked:

```python
1. Feature Collection:
   - Gather all 16 input values from form
   - Convert to NumPy array

2. Feature Preprocessing:
   - Apply StandardScaler transformation
   - Normalize features using training statistics

3. Model Inference:
   - Pass scaled features to trained classifier
   - Generate prediction and probability scores

4. Output Processing:
   - Decode numerical class to bean type name
   - Display result to user interface
```

---

## Machine Learning Model

### Model Specifications

#### Input Features (16)

| # | Feature Name | Description | Unit |
|---|--------------|------------|------|
| 1 | Area | Bean area in pixel coordinates | pixelsÂ² |
| 2 | Perimeter | Bean boundary length | pixels |
| 3 | Major Axis Length | Length of primary axis | pixels |
| 4 | Minor Axis Length | Length of secondary axis | pixels |
| 5 | Aspect Ratio | Ratio of major to minor axis | unitless |
| 6 | Eccentricity | Elongation measurement | 0-1 |
| 7 | Convex Area | Area of convex hull | pixelsÂ² |
| 8 | Equivalent Diameter | Circular equivalent diameter | pixels |
| 9 | Extent | Ratio of area to bounding rectangle | unitless |
| 10 | Solidity | Ratio of area to convex area | unitless |
| 11 | Roundness | Roundness metric | unitless |
| 12 | Compactness | Compactness coefficient | unitless |
| 13 | ShapeFactor1 | Shape descriptor 1 | unitless |
| 14 | ShapeFactor2 | Shape descriptor 2 | unitless |
| 15 | ShapeFactor3 | Shape descriptor 3 | unitless |
| 16 | ShapeFactor4 | Shape descriptor 4 | unitless |

#### Output Classes (7)

1. **SEKER** - Small, round beans
2. **BARBUNYA** - Large, kidney-shaped beans
3. **BOMBAY** - Small, dark beans
4. **CALI** - Large, light-colored beans
5. **HOROZ** - Medium-sized beans
6. **SIRA** - Small, dark beans
7. **DERMASON** - Medium-large beans

### Training Methodology

**Dataset Characteristics:**
- Total Samples: 13,611
- Features: 16 morphological measurements
- Classes: 7 bean types
- Feature Extraction: Image processing and morphological analysis

**Preprocessing Pipeline:**
```
Raw Features
    â†“
Missing Value Handling
    â†“
Outlier Detection
    â†“
StandardScaler Normalization
    â†“
Processed Features
```

**Model Architecture:**
- Algorithm: Supervised Classification Model
- Regularization: Applied during training
- Cross-Validation: K-Fold validation for robustness
- Optimization: Scikit-learn optimized algorithms

---

## Technical Implementation

### Technology Stack

```
Frontend:     Streamlit 1.28.0+
Backend:      Python 3.8+
ML Framework: Scikit-learn 1.3.0+
Data Tools:   Pandas 2.0.0+, NumPy 1.24.0+
Visualization: Matplotlib 3.7.0+, Seaborn 0.12.0+
Serialization: Joblib 1.3.0+
Notebook:     Jupyter 1.0.0+
```

### Core Dependencies

```
streamlit>=1.28.0          # Web framework
scikit-learn>=1.3.0        # ML algorithms
pandas>=2.0.0              # Data processing
numpy>=1.24.0              # Numerical computing
joblib>=1.3.0              # Model persistence
matplotlib>=3.7.0          # Visualization
seaborn>=0.12.0            # Statistical plotting
jupyter>=1.0.0             # Interactive notebooks
```

### Model Files

| File | Size | Purpose |
|------|------|---------|
| `model.pkl` | ~50-100 MB | Trained classifier |
| `scaler.pkl` | ~5-10 KB | StandardScaler object |
| `lebel.pkl` | ~1-5 KB | Label encoder |

---

## Installation & Deployment

### Local Installation

```bash
# 1. Clone repository
git clone https://github.com/myselfsukhendu09/Dry-Bean-Type-Classification.git
cd Dry-Bean-Type-Classification

# 2. Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Run application
streamlit run app.py
```

### Application Access

```
Local: http://localhost:8501
```

### Cloud Deployment Options

#### Streamlit Cloud
```bash
# Push to GitHub, then deploy via Streamlit Cloud dashboard
# Free tier available with GitHub integration
```

#### Docker Containerization
```dockerfile
FROM python:3.10-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["streamlit", "run", "app.py"]
```

#### Heroku Deployment
```bash
git push heroku main
```

---

## Usage Guidelines

### For End Users

**Step-by-Step Prediction Process:**

1. **Access Application**
   - Open Streamlit app in web browser
   - Ensure stable internet connection

2. **Input Bean Measurements**
   - Enter 16 morphological feature values
   - Use decimal format (e.g., 1234.56)
   - Ensure values match your bean measurements

3. **Trigger Prediction**
   - Click "Predict Bean Type" button
   - Wait for model inference (typically <1 second)

4. **Interpret Results**
   - Review predicted bean classification
   - Green checkmark indicates successful prediction
   - Bold text shows the predicted category

### For Developers

**Integration Examples:**

```python
import joblib
import numpy as np

# Load model components
model = joblib.load("model.pkl")
scaler = joblib.load("scaler.pkl")
label_encoder = joblib.load("lebel.pkl")

# Prepare features (16 values)
features = np.array([[area, perimeter, ...other_14_features...]]).reshape(1, -1)

# Scale and predict
scaled = scaler.transform(features)
prediction = model.predict(scaled)
bean_type = label_encoder.inverse_transform(prediction)[0]

print(f"Predicted Bean Type: {bean_type}")
```

---

## Performance Metrics

### Model Evaluation

See the Jupyter notebook for comprehensive metrics including:

**Classification Metrics:**
- **Accuracy**: Overall correctness across all classes
- **Precision**: True positive rate per class
- **Recall**: Detection rate per class
- **F1-Score**: Harmonic mean of precision and recall

**Advanced Analysis:**
- Confusion Matrix visualization
- Per-class performance breakdown
- ROC curves and AUC scores
- Feature importance rankings

**Validation Strategy:**
- K-Fold Cross-Validation
- Train-Test Split: 80-20 ratio
- Stratified sampling for class balance

---

## Monitoring & Maintenance

### Best Practices

1. **Data Quality**
   - Validate input ranges
   - Monitor feature distributions
   - Alert on anomalous patterns

2. **Model Monitoring**
   - Track prediction confidence
   - Log prediction history
   - Monitor for concept drift

3. **System Health**
   - Regular application testing
   - Dependency updates
   - Performance benchmarking

### Future Enhancements

- [ ] Batch prediction API
- [ ] Model explainability (SHAP values)
- [ ] Real-time model retraining pipeline
- [ ] Advanced analytics dashboard
- [ ] Multi-model ensemble approach
- [ ] REST API development
- [ ] Mobile application
- [ ] Production-grade CI/CD pipeline

---

## Support & Resources

**Documentation:**
- [Streamlit Documentation](https://docs.streamlit.io)
- [Scikit-learn Documentation](https://scikit-learn.org)
- [Project GitHub Repository](https://github.com/myselfsukhendu09/Dry-Bean-Type-Classification)

**Author:** Sukhendu Biswas (Batch 12)  
**GitHub:** https://github.com/myselfsukhendu09  
**Project Date:** January 2026

---

## Conclusion

The Dry Bean Type Classification System represents a complete, production-ready solution for automated bean classification. With its user-friendly Streamlit interface, robust machine learning foundation, and comprehensive documentation, it serves as an excellent example of modern machine learning application development.

**Status:** âœ… Production Ready
